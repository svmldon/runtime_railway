{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data):\n",
    "    with open(str(data)+str(i)+'.csv', 'w') as myfile:\n",
    "        wr = csv.writer(myfile)\n",
    "        for val in data:\n",
    "            wr.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(ys):\n",
    "    #ys = ys[~ys.isnull()]\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    y = []\n",
    "    for i in ys:\n",
    "        if (i>=lower_bound and i<=upper_bound):\n",
    "            y.append(i)\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_f(y):\n",
    "    xv=[]\n",
    "    yv=[]\n",
    "    freq = collections.Counter(y)\n",
    "    for b in freq.keys():\n",
    "        if (str(b)!=\"nan\"):\n",
    "            xv.append(b)\n",
    "    xv = sorted(xv)\n",
    "    yv = [freq[a] for a in xv]\n",
    "    xv = [int(m) for m in xv]\n",
    "    return (xv[yv.index(max(yv))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution(object):\n",
    "    def __init__(self,dist_names_list = []):\n",
    "        self.dist_names = ['alpha',\n",
    "                            #'anglit',\n",
    "                            #'arcsine',\n",
    "                            'argus',\n",
    "                            'beta',\n",
    "                            'betaprime',\n",
    "                            'bradford',\n",
    "                            'burr',\n",
    "                            'burr12',\n",
    "                            'cauchy',\n",
    "                            'chi',\n",
    "                            'chi2',\n",
    "                            #'cosine',\n",
    "                            'crystalball',\n",
    "                            'dgamma',\n",
    "                            'dweibull',\n",
    "                            #'erlang',\n",
    "                            'expon',\n",
    "                            'exponnorm',\n",
    "                            'exponweib',\n",
    "                            'exponpow',\n",
    "                            'f',\n",
    "                            'fatiguelife',\n",
    "                            'fisk',\n",
    "                            'foldcauchy',\n",
    "                            'foldnorm',\n",
    "                            #'frechet_r',\n",
    "                            #'frechet_l',\n",
    "                            'genlogistic',\n",
    "                            'gennorm',\n",
    "                            'genpareto',\n",
    "                            'genexpon',\n",
    "                            'genextreme',\n",
    "                            #'gausshyper',\n",
    "                            'gamma',\n",
    "                            'gengamma',\n",
    "                            'genhalflogistic',\n",
    "                            'gilbrat',\n",
    "                            'gompertz',\n",
    "                            'gumbel_r',\n",
    "                            'gumbel_l',\n",
    "                            'halfcauchy',\n",
    "                            'halflogistic',\n",
    "                            'halfnorm',\n",
    "                            'halfgennorm',\n",
    "                            'hypsecant',\n",
    "                            'invgamma',\n",
    "                            'invgauss',\n",
    "                            'invweibull',\n",
    "                            'johnsonsb',\n",
    "                            'johnsonsu',\n",
    "                            'kappa4',\n",
    "                            'kappa3',\n",
    "                            'ksone',\n",
    "                            'kstwobign',\n",
    "                            'laplace',\n",
    "                            'levy',\n",
    "                            'levy_l',\n",
    "                            #'levy_stable',\n",
    "                            'logistic',\n",
    "                            'loggamma',\n",
    "                            'loglaplace',\n",
    "                            'lognorm',\n",
    "                            'lomax',\n",
    "                            'maxwell',\n",
    "                            'mielke',\n",
    "                            'moyal',\n",
    "                            'nakagami',\n",
    "                            'ncx2',\n",
    "                            #'ncf',\n",
    "                            'nct',\n",
    "                            'norm',\n",
    "                            'norminvgauss',\n",
    "                            'pareto',\n",
    "                            'pearson3',\n",
    "                            'powerlaw',\n",
    "                            'powerlognorm',\n",
    "                            'powernorm',\n",
    "                            'rdist',\n",
    "                            'reciprocal',\n",
    "                            'rayleigh',\n",
    "                            'rice',\n",
    "                            'recipinvgauss',\n",
    "                            'semicircular',\n",
    "                            'skewnorm',\n",
    "                            't',\n",
    "                            'trapz',\n",
    "                            'triang',\n",
    "                            'truncexpon',\n",
    "                            'truncnorm',\n",
    "                            'tukeylambda',\n",
    "                            #'uniform',\n",
    "                            'vonmises',\n",
    "                            'vonmises_line',\n",
    "                            'wald',\n",
    "                            'weibull_min',\n",
    "                            'weibull_max',\n",
    "                            'wrapcauchy']\n",
    "        \"\"\"self.dist_names = ['weibull_min',\n",
    "                            'weibull_max',\n",
    "                           'beta',\n",
    "                            'chi2',\n",
    "                            'f',\n",
    "                            'gamma',\n",
    "                            'logistic',\n",
    "                            'loggamma',\n",
    "                            'lognorm',\n",
    "                            'norm',\n",
    "                            'pearson3']\"\"\"\n",
    "        self.dist_results = []\n",
    "        self.params = {}        \n",
    "        self.DistributionName = \"\"\n",
    "        self.PValue = 0\n",
    "        self.Param = None\n",
    "\n",
    "        self.isFitted = False\n",
    "\n",
    "    def Fit(self, y):\n",
    "        self.dist_results = []\n",
    "        self.params = {}\n",
    "        for dist_name in self.dist_names:\n",
    "            print(dist_name)\n",
    "            dist = getattr(scipy.stats, dist_name)\n",
    "            param = dist.fit(y)\n",
    "\n",
    "            self.params[dist_name] = param\n",
    "            #Applying the Kolmogorov-Smirnov test\n",
    "            D, p = scipy.stats.kstest(y, dist_name, args=param);\n",
    "            #print(p)\n",
    "            self.dist_results.append((dist_name,p))\n",
    "\n",
    "        #select the best fitted distribution\n",
    "        sel_dist,p = (max(self.dist_results,key=lambda item:item[1]))\n",
    "        #store the name of the best fit and its p value\n",
    "        self.DistributionName = sel_dist\n",
    "        self.PValue = p\n",
    "\n",
    "        self.isFitted = True\n",
    "        print(self.DistributionName)\n",
    "        print(self.PValue)\n",
    "        return (self.DistributionName,self.PValue)\n",
    "\n",
    "    def Random(self, n = 1):\n",
    "        if self.isFitted:\n",
    "            dist_name = self.DistributionName\n",
    "            param = self.params[dist_name]\n",
    "            #initiate the scipy distribution\n",
    "            dist = getattr(scipy.stats, dist_name)\n",
    "            return dist.rvs(*param[:-2], loc=param[-2], scale=param[-1], size=n)\n",
    "        else:\n",
    "            raise ValueError('Must first run the Fit method.')\n",
    "    def Plot1(self,y):\n",
    "        x = self.Random(n=len(y))\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        sns.distplot(y, rug=True, hist=True,label='Actual')\n",
    "        sns.distplot(x, rug=True, hist=True, label='Fitted')\n",
    "        \"\"\"plt.plot(x, alpha=0.5, label='Fitted')\n",
    "        plt.plot(y, alpha=0.5, label='Actual')\"\"\"\n",
    "        plt.legend()\n",
    "        plt.savefig('DN'+str(i+1)+'.'+str(j-2)+'Block ['+str(column[j])+'] TRAIN ['+str(wtt_d.iloc[i,0])+'] '+str(type1)+'.png',dpi=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize():\n",
    "    #Runtime of each individual train standardized\n",
    "    for l in range(8):\n",
    "        for i in column1:\n",
    "            if (l<4):\n",
    "                for j in train_up:   \n",
    "                    mean = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].mean(axis = 0, skipna = True))\n",
    "                    std = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].std(axis = 0, skipna = True))\n",
    "                    rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i] = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i]-mean)/std \n",
    "            else:\n",
    "                for j in train_dn:      \n",
    "                    mean = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].mean(axis = 0, skipna = True))\n",
    "                    std = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].std(axis = 0, skipna = True))\n",
    "                    rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i] = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max():\n",
    "    #Runtime of each individual train normalised\n",
    "    for l in range(8):\n",
    "        for i in column1:\n",
    "            if (l<4):\n",
    "                for j in train_up:   \n",
    "                    mean = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].mean(axis = 0, skipna = True))\n",
    "                    max_ = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].max(axis = 0, skipna = True))\n",
    "                    min_ = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].min(axis = 0, skipna = True))\n",
    "                    rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i] = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i]-mean)/(max_ - min_) \n",
    "            else:\n",
    "                for j in train_dn:      \n",
    "                    mean = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].mean(axis = 0, skipna = True))\n",
    "                    max_ = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].max(axis = 0, skipna = True))\n",
    "                    min_ = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].min(axis = 0, skipna = True))\n",
    "                    rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i] = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i]-mean)/(max_ - min_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "    #Runtime of each individual train divided by mean\n",
    "    for l in range(8):\n",
    "        for i in column1:\n",
    "            if (l<4):\n",
    "                for j in train_up:   \n",
    "                    mean = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].mean(axis = 0, skipna = True))\n",
    "                    rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i] = rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i]/mean \n",
    "            else:\n",
    "                for j in train_dn:      \n",
    "                    mean = (rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i].mean(axis = 0, skipna = True))\n",
    "                    rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i] = rt_names[l].loc[rt_names[l]['TrainMaskNo']==j,i]/mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal():\n",
    "    rt_mean = []\n",
    "    for i in rt_names:\n",
    "        rt_mean.append(i.mean(axis = 0, skipna = True) )\n",
    "    for i in range(8):\n",
    "        #Actual Runtimes 8 files\n",
    "        runtime = rt_names[i]\n",
    "        #Supplies different values of mean for UP/DN 00,01,10..\n",
    "        mean = rt_mean[i]\n",
    "        # Block wise info\n",
    "        for j in column1:\n",
    "            runtime[j] = runtime[j]/mean[j]\n",
    "        rt_names[i] = runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_conversion(data2):\n",
    "    clt_values = []\n",
    "    data1 = data2.values\n",
    "    data = [k for k in data1 if str(k) != 'nan']\n",
    "    length = len(data)\n",
    "    if (length<20):\n",
    "        clt_values.append(np.nan)\n",
    "        return(clt_values)\n",
    "    for i in range(length):\n",
    "        sample1 = random.sample(data, math.floor(length/2))\n",
    "        clt_values.append(statistics.mean(sample1))\n",
    "    return(clt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_conversion_10_per_org(data2):\n",
    "    clt_values = []\n",
    "    data1 = data2.values\n",
    "    data = [k for k in data1 if str(k) != 'nan']\n",
    "    length = len(data)\n",
    "    if (length<20):\n",
    "        clt_values.append(np.nan)\n",
    "        return(clt_values)\n",
    "    for i in range(length):\n",
    "        sample1 = random.sample(data, math.floor(length*0.1))\n",
    "        clt_values.append(statistics.mean(sample1))\n",
    "    return(clt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_conversion_10_per_150_org(data2):\n",
    "    clt_values = []\n",
    "    data1 = data2.values\n",
    "    data = [k for k in data1 if str(k) != 'nan']\n",
    "    length = len(data)\n",
    "    if (length<20):\n",
    "        clt_values.append(np.nan)\n",
    "        return(clt_values)\n",
    "    for i in range(math.floor(0.5*length)):\n",
    "        sample1 = random.sample(data, math.floor(length*0.05))\n",
    "        clt_values.append(statistics.mean(sample1))\n",
    "    return(clt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_conversion_10_per_30(data2):\n",
    "    clt_values = []\n",
    "    data1 = data2.values\n",
    "    data = [k for k in data1 if str(k) != 'nan']\n",
    "    length = len(data)\n",
    "    if (length<20):\n",
    "        clt_values.append(np.nan)\n",
    "        return(clt_values)\n",
    "    if (length>100):\n",
    "        for i in range(100):\n",
    "            sample1 = random.sample(data, math.floor(length*0.1))\n",
    "            clt_values.append(statistics.mean(sample1))\n",
    "    else:\n",
    "        for i in range(30):\n",
    "            sample1 = random.sample(data, math.floor(length*0.1))\n",
    "            clt_values.append(statistics.mean(sample1))\n",
    "    return(clt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot_block(data,generated_data,i,j):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.distplot(data, rug=True, hist=False, label='Actual')\n",
    "    sns.distplot(generated_data, rug=True, hist=False, label='Fitted')\n",
    "    \n",
    "    #plt.text(wttv,0.1,'wtt'+str(wtt_t),rotation=90)\n",
    "    #plt.axvline(x=crt, color='b')\n",
    "    #plt.text(crt,0,'crt'+str(type1),rotation=90)\n",
    "    plt.legend(prop={'size': 16}, title = 'Block-'+str(column[j])+\" plot type\"+plot_type[i])\n",
    "    plt.title('Density Plot with Runtime')\n",
    "    plt.xlabel('Runtime')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Block-'+str(column[j])+\" \"+plot_type[i]+'.png',dpi=200)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot_train(data,original_data,generated_data,i,j,l):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.distplot(data, rug=True, hist=False, label='CLT data')\n",
    "    sns.distplot(generated_data, rug=True, hist=False, label='Fitted data')\n",
    "    sns.distplot(original_data, rug=True, hist=False, label='Original data')\n",
    "    if (i>3):\n",
    "        wttv = wtt_d.iloc[l,j]\n",
    "        wtt_t = wtt_type_d.iloc[l,j]\n",
    "    else:\n",
    "        wttv = wtt_u.iloc[l,j]\n",
    "        wtt_t = wtt_type_u.iloc[l,j]\n",
    "    plt.axvline(x=wttv, color='r')\n",
    "    plt.text(wttv,0.1,'wtt'+str(wtt_t),rotation=90)\n",
    "    crt = crt_names[i].iloc[l,j]\n",
    "    plt.axvline(x=crt, color='b')\n",
    "    plt.text(crt,0,'crt',rotation=90)\n",
    "    if (i>3):\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    else:\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    plt.title('Density Plot with Runtime')\n",
    "    plt.xlabel('Runtime')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    if (i>3):\n",
    "        plt.savefig(results_dir+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)\n",
    "    else:\n",
    "        plt.savefig(results_dir+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_plot_train(data,original_data,generated_data,i,j,l):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.kdeplot(data,cumulative=True,label='CLT data')\n",
    "    sns.kdeplot(generated_data,cumulative=True,label='Fitted data')\n",
    "    sns.kdeplot(original_data,cumulative=True,label='Original data')\n",
    "    if (i>3):\n",
    "        wttv = wtt_d.iloc[l,j]\n",
    "        wtt_t = wtt_type_d.iloc[l,j]\n",
    "    else:\n",
    "        wttv = wtt_u.iloc[l,j]\n",
    "        wtt_t = wtt_type_u.iloc[l,j]\n",
    "    plt.axvline(x=wttv, color='r')\n",
    "    plt.text(wttv,0.1,'wtt'+str(wtt_t),rotation=90)\n",
    "    crt = crt_names[i].iloc[l,j]\n",
    "    plt.axvline(x=crt, color='b')\n",
    "    plt.text(crt,0,'crt',rotation=90)\n",
    "    if (i>3):\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    else:\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    plt.title('CDF Plot with Runtime')\n",
    "    plt.xlabel('Runtime')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    if (i>3):\n",
    "        plt.savefig(results_dir1+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)\n",
    "    else:\n",
    "        plt.savefig(results_dir1+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot_train(data,original_data,generated_data,i,j,l):\n",
    "    plt.figure()\n",
    "    #Code for count plot of clt data but as data is continuous so\n",
    "    # So discarded\n",
    "    \"\"\"xv=[]\n",
    "    yv=[]\n",
    "    freq = collections.Counter(data)\n",
    "    for b in freq.keys():\n",
    "        if (str(b)!=\"nan\"):\n",
    "            xv.append(b)\n",
    "    xv = sorted(xv)\n",
    "    yv = [freq[a] for a in xv]\n",
    "    xv = [int(m) for m in xv]\n",
    "    if (len(xv)<2):\n",
    "        return\n",
    "    akima = Akima1DInterpolator(xv, yv)\n",
    "    x1_new = np.linspace(min(xv), max(xv), 1000)\n",
    "    plt.plot(xv, yv, 'bo')\n",
    "    plt.plot(x1_new, akima(x1_new), 'b', label='CLT data')\"\"\"\n",
    "    \n",
    "    #Code for count plot of original data\n",
    "    xv_od=[]\n",
    "    yv_od=[]\n",
    "    freq_od = collections.Counter(original_data)\n",
    "    for b in freq_od.keys():\n",
    "        if (str(b)!=\"nan\"):\n",
    "            xv_od.append(b)\n",
    "    xv_od = sorted(xv_od)\n",
    "    yv_od = [freq_od[a] for a in xv_od]\n",
    "    xv_od = [int(m) for m in xv_od]\n",
    "    if (len(xv_od)<2):\n",
    "        return\n",
    "    akima_od = Akima1DInterpolator(xv_od, yv_od)\n",
    "    x1_new_od = np.linspace(min(xv_od), max(xv_od), 1000)\n",
    "    plt.plot(xv_od, yv_od, 'bo')\n",
    "    plt.plot(x1_new_od, akima_od(x1_new_od), 'b', label='Original data')\n",
    "    \n",
    "    #Code for count plot of generated data but as data is continuous so\n",
    "    # So discarded\n",
    "    \"\"\"xv_gd=[]\n",
    "    yv_gd=[]\n",
    "    freq_gd = collections.Counter(generated_data)\n",
    "    for b in freq_gd.keys():\n",
    "        if (str(b)!=\"nan\"):\n",
    "            xv_gd.append(b)\n",
    "    xv_gd = sorted(xv_gd)\n",
    "    yv_gd = [freq_gd[a] for a in xv_gd]\n",
    "    xv_gd = [int(m) for m in xv_gd]\n",
    "    if (len(xv_gd)<2):\n",
    "        return\n",
    "    akima_gd = Akima1DInterpolator(xv_gd, yv_gd)\n",
    "    x1_new_gd = np.linspace(min(xv_gd), max(xv_gd), 1000)\n",
    "    plt.plot(xv_gd, yv_gd, 'bo')\n",
    "    plt.plot(x1_new_gd, akima_gd(x1_new_gd), 'b', label='Generated data')\"\"\"\n",
    "    \n",
    "    \n",
    "    if (i>3):\n",
    "        wttv = wtt_d.iloc[l,j]\n",
    "        wtt_t = wtt_type_d.iloc[l,j]\n",
    "    else:\n",
    "        wttv = wtt_u.iloc[l,j]\n",
    "        wtt_t = wtt_type_u.iloc[l,j]\n",
    "    plt.axvline(x=wttv, color='r')\n",
    "    plt.text(wttv,0.1,'wtt'+str(wtt_t),rotation=90)\n",
    "    crt = crt_names[i].iloc[l,j]\n",
    "    plt.axvline(x=crt, color='b')\n",
    "    plt.text(crt,0,'crt',rotation=90)\n",
    "    if (i>3):\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    else:\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    plt.title('Count Plot with Runtime')\n",
    "    plt.xlabel('Runtime')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True)\n",
    "    if (i>3):\n",
    "        plt.savefig(results_dir2+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)\n",
    "    else:\n",
    "        plt.savefig(results_dir2+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_train(data,original_data,generated_data,i,j,l):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.boxplot(original_data)\n",
    "    sns.swarmplot(original_data,color=\"blue\",label='Original data')\n",
    "    \"\"\"sns.boxplot(data)\n",
    "    sns.swarmplot(data,color=\"red\",label='CLT data')\n",
    "    sns.boxplot(generated_data)\n",
    "    sns.swarmplot(generated_data,color=\"green\",label='Fitted data')\"\"\"\n",
    "    if (i>3):\n",
    "        wttv = wtt_d.iloc[l,j]\n",
    "        wtt_t = wtt_type_d.iloc[l,j]\n",
    "    else:\n",
    "        wttv = wtt_u.iloc[l,j]\n",
    "        wtt_t = wtt_type_u.iloc[l,j]\n",
    "    plt.axvline(x=wttv, color='r')\n",
    "    plt.text(wttv,0.1,'wtt'+str(wtt_t),rotation=90)\n",
    "    crt = crt_names[i].iloc[l,j]\n",
    "    plt.axvline(x=crt, color='b')\n",
    "    plt.text(crt,0,'crt',rotation=90)\n",
    "    if (i>3):\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    else:\n",
    "        plt.legend(prop={'size': 8}, title = 'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"\\n Plot Type-\"+plot_type[i])\n",
    "    plt.title('Box Plot with swarm')\n",
    "    plt.xlabel('Runtime')\n",
    "    plt.ylabel('Swarm')\n",
    "    plt.grid(True)\n",
    "    if (i>3):\n",
    "        plt.savefig(results_dir3+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_d.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)\n",
    "    else:\n",
    "        plt.savefig(results_dir3+str(j-2)+'.'+str(l+1)+'Block-'+str(column[j])+\"Train-\"+str(wtt_u.iloc[l,0])+\"_\"+plot_type[i]+'.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nan(i,l,j):\n",
    "    if (i>3):\n",
    "        cal_d_delay.iloc[l,j] = np.nan\n",
    "        comp_d_delay.iloc[l,j] = np.nan\n",
    "        mode_d_delay.iloc[l,j] = np.nan\n",
    "        wtt_d_delay.iloc[l,j] = np.nan\n",
    "        cal_d_infra.iloc[l,j] = np.nan\n",
    "        comp_d_infra.iloc[l,j] = np.nan\n",
    "        mode_d_infra.iloc[l,j] = np.nan\n",
    "        wtt_d_infra.iloc[l,j] = np.nan\n",
    "    else:\n",
    "        cal_u_delay.iloc[l,j] = np.nan\n",
    "        comp_u_delay.iloc[l,j] = np.nan\n",
    "        mode_u_delay.iloc[l,j] = np.nan\n",
    "        wtt_u_delay.iloc[l,j] = np.nan\n",
    "        cal_u_infra.iloc[l,j] = np.nan\n",
    "        comp_u_infra.iloc[l,j] = np.nan\n",
    "        mode_u_infra.iloc[l,j] = np.nan\n",
    "        wtt_u_infra.iloc[l,j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname('__file__')\n",
    "results_dir = os.path.join(script_dir, 'Indv_train/')\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "#script_dir = os.path.dirname('__file__')\n",
    "results_dir1 = os.path.join(script_dir, 'Indv_train_CDF/')\n",
    "if not os.path.isdir(results_dir1):\n",
    "    os.makedirs(results_dir1)\n",
    "    \n",
    "#script_dir = os.path.dirname('__file__')\n",
    "results_dir2 = os.path.join(script_dir, 'Indv_train_count/')\n",
    "if not os.path.isdir(results_dir2):\n",
    "    os.makedirs(results_dir2)\n",
    "    \n",
    "#script_dir = os.path.dirname('__file__')\n",
    "results_dir3 = os.path.join(script_dir, 'Indv_train_box/')\n",
    "if not os.path.isdir(results_dir3):\n",
    "    os.makedirs(results_dir3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
