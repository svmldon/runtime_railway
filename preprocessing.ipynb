{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.interpolate import Akima1DInterpolator\n",
    "import collections\n",
    "#import http.client\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Time table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtt = pd.ExcelFile(\"Current WTT wo traffic allowances.xlsx\")\n",
    "#print(realdata1.sheet_names)\n",
    "wtt_d = wtt.parse(\"WTT wo Traffic Allow DN\",skiprows=1)\n",
    "wtt_d = wtt_d.replace('$', np.nan)\n",
    "wtt_d = wtt_d.replace(to_replace=0, value=np.nan)\n",
    "wtt_u = wtt.parse(\"WTT wo Traffic Allow UP\",skiprows=1)\n",
    "wtt_u = wtt_u.replace('$', np.nan)\n",
    "wtt_u = wtt_u.replace(to_replace=0, value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stoppage information from working timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtt_type = pd.ExcelFile(\"WTT Stoppages.xlsx\")\n",
    "wtt_type_d = wtt_type.parse(\"WTT DN Stops\",skiprows=0)\n",
    "for i in (np.arange(0,54)):\n",
    "    for j in (np.arange(3,61)):\n",
    "        a = wtt_type_d.iloc[i,j] \n",
    "        a = a.replace('\"', '')\n",
    "        wtt_type_d.iloc[i,j] = a\n",
    "wtt_type_u = wtt_type.parse(\"WTT UP Stops\",skiprows=0)\n",
    "for i in (np.arange(0,54)):\n",
    "    for j in (np.arange(3,61)):\n",
    "        a = wtt_type_u.iloc[i,j] \n",
    "        a = a.replace('\"', '')\n",
    "        wtt_type_u.iloc[i,j] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computed Runtime by TCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crt = pd.ExcelFile(\"Computed RT ver 2.xlsx\")\n",
    "crt_dn_00 = crt.parse(\"RunTime DN 00\",skiprows=0)\n",
    "crt_dn_00 = crt_dn_00.replace('$', np.nan)\n",
    "crt_dn_00 = crt_dn_00.replace(to_replace=0, value=np.nan)\n",
    "crt_dn_01 = crt.parse(\"RunTime DN 01\",skiprows=0)\n",
    "crt_dn_01 = crt_dn_01.replace('$', np.nan)\n",
    "crt_dn_01 = crt_dn_01.replace(to_replace=0, value=np.nan)\n",
    "crt_dn_10 = crt.parse(\"RunTime DN 10\",skiprows=0)\n",
    "crt_dn_10 = crt_dn_10.replace('$', np.nan)\n",
    "crt_dn_10 = crt_dn_10.replace(to_replace=0, value=np.nan)\n",
    "crt_dn_11 = crt.parse(\"RunTime DN 11\",skiprows=0)\n",
    "crt_dn_11 = crt_dn_11.replace('$', np.nan)\n",
    "crt_dn_11 = crt_dn_11.replace(to_replace=0, value=np.nan)\n",
    "crt_up_00 = crt.parse(\"RunTime UP 00\",skiprows=0)\n",
    "crt_up_00 = crt_dn_00.replace('$', np.nan)\n",
    "crt_up_00 = crt_dn_00.replace(to_replace=0, value=np.nan)\n",
    "crt_up_01 = crt.parse(\"RunTime UP 01\",skiprows=0)\n",
    "crt_up_01 = crt_dn_01.replace('$', np.nan)\n",
    "crt_up_01 = crt_dn_01.replace(to_replace=0, value=np.nan)\n",
    "crt_up_10 = crt.parse(\"RunTime UP 10\",skiprows=0)\n",
    "crt_up_10 = crt_dn_10.replace('$', np.nan)\n",
    "crt_up_10 = crt_dn_10.replace(to_replace=0, value=np.nan)\n",
    "crt_up_11 = crt.parse(\"RunTime UP 11\",skiprows=0)\n",
    "crt_up_11 = crt_dn_11.replace('$', np.nan)\n",
    "crt_up_11 = crt_dn_11.replace(to_replace=0, value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = list(wtt_d.columns.values)\n",
    "column1 = column[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Realized Runtime Divided by halt type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sufiyan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/sufiyan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n",
      "/home/sufiyan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  if sys.path[0] == '':\n",
      "/home/sufiyan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "rt_00 = pd.read_csv(\"RT 00.csv\",skiprows=1)\n",
    "rt_00 = rt_00.replace('$', np.nan)\n",
    "rt_00 = rt_00.replace(to_replace=0, value=np.nan)\n",
    "rt_00[column1] = rt_00[column1].convert_objects(convert_numeric=True)\n",
    "rt_01 = pd.read_csv(\"RT 01.csv\",skiprows=1)\n",
    "rt_01 = rt_01.replace('$', np.nan)\n",
    "rt_01 = rt_01.replace(to_replace=0, value=np.nan)\n",
    "rt_01[column1] = rt_01[column1].convert_objects(convert_numeric=True)\n",
    "rt_10 = pd.read_csv(\"RT 10.csv\",skiprows=1)\n",
    "rt_10 = rt_10.replace('$', np.nan)\n",
    "rt_10 = rt_10.replace(to_replace=0, value=np.nan)\n",
    "rt_10[column1] = rt_10[column1].convert_objects(convert_numeric=True)\n",
    "rt_11 = pd.read_csv(\"RT 11.csv\",skiprows=1)\n",
    "rt_11 = rt_11.replace('$', np.nan)\n",
    "rt_11 = rt_11.replace(to_replace=0, value=np.nan)\n",
    "rt_11[column1] = rt_11[column1].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Realized Runtime Divided by halt type and direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_00_up = rt_00[rt_00['Direction']=='U']\n",
    "rt_01_up = rt_01[rt_01['Direction']=='U']\n",
    "rt_10_up = rt_10[rt_10['Direction']=='U']\n",
    "rt_11_up = rt_11[rt_11['Direction']=='U']\n",
    "rt_00_dn = rt_00[rt_00['Direction']=='D']\n",
    "rt_01_dn = rt_01[rt_01['Direction']=='D']\n",
    "rt_10_dn = rt_10[rt_10['Direction']=='D']\n",
    "rt_11_dn = rt_11[rt_11['Direction']=='D']\n",
    "#data = data[data['Speed Class']=='RAJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_names = [rt_00_up, rt_01_up, rt_10_up, rt_11_up, rt_00_dn, rt_01_dn, rt_10_dn, rt_11_dn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(ys):\n",
    "    ys = ys[~ys.isnull()]\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return (lower_bound,upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_00_d = 0 #lower quantile limit in down direction\n",
    "l_01_d = 0\n",
    "l_10_d = 0\n",
    "l_11_d = 0\n",
    "l_00_u = 0\n",
    "l_01_u = 0\n",
    "l_10_u = 0\n",
    "l_11_u = 0\n",
    "u_00_d = 0 #upper quantile limit in up direction\n",
    "u_01_d = 0\n",
    "u_10_d = 0\n",
    "u_11_d = 0\n",
    "u_00_u = 0\n",
    "u_01_u = 0\n",
    "u_10_u = 0\n",
    "u_11_u = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(lower_limit,upper_limit,train_no,block_no,direction,halt_type):\n",
    "    if (direction=='D'):\n",
    "        if (halt_type=='00'):\n",
    "            for i in range(len(rt_00_dn.index)):\n",
    "                if (rt_00_dn.iloc[i,0]==wtt_d.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_00_dn.iloc[i,block_no]>upper_limit or rt_00_dn.iloc[i,block_no]<lower_limit):\n",
    "                            rt_00_dn.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_00_dn.iloc[i,block_no]=np.nan\n",
    "        if (halt_type=='01'):\n",
    "            for i in range(len(rt_01_dn.index)):\n",
    "                if (rt_01_dn.iloc[i,0]==wtt_d.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_01_dn.iloc[i,block_no]>upper_limit or rt_01_dn.iloc[i,block_no]<lower_limit):\n",
    "                            rt_01_dn.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_01_dn.iloc[i,block_no]=np.nan\n",
    "        if (halt_type=='10'):\n",
    "            for i in range(len(rt_10_dn.index)):\n",
    "                if (rt_10_dn.iloc[i,0]==wtt_d.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_10_dn.iloc[i,block_no]>upper_limit or rt_10_dn.iloc[i,block_no]<lower_limit):\n",
    "                            rt_10_dn.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_10_dn.iloc[i,block_no]=np.nan\n",
    "        if (halt_type=='11'):\n",
    "            for i in range(len(rt_11_dn.index)):\n",
    "                if (rt_11_dn.iloc[i,0]==wtt_d.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_11_dn.iloc[i,block_no]>upper_limit or rt_11_dn.iloc[i,block_no]<lower_limit):\n",
    "                            rt_11_dn.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_11_dn.iloc[i,block_no]=np.nan\n",
    "    if (direction=='U'):\n",
    "        if (halt_type=='00'):\n",
    "            for i in range(len(rt_00_up.index)):\n",
    "                if (rt_00_up.iloc[i,0]==wtt_u.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_00_up.iloc[i,block_no]>upper_limit or rt_00_up.iloc[i,block_no]<lower_limit):\n",
    "                            rt_00_up.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_00_up.iloc[i,block_no]=np.nan\n",
    "        if (halt_type=='01'):\n",
    "            for i in range(len(rt_01_up.index)):\n",
    "                if (rt_01_up.iloc[i,0]==wtt_u.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_01_up.iloc[i,block_no]>upper_limit or rt_01_up.iloc[i,block_no]<lower_limit):\n",
    "                            rt_01_up.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_01_up.iloc[i,block_no]=np.nan\n",
    "        if (halt_type=='10'):\n",
    "            for i in range(len(rt_10_up.index)):\n",
    "                if (rt_10_up.iloc[i,0]==wtt_u.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_10_up.iloc[i,block_no]>upper_limit or rt_10_up.iloc[i,block_no]<lower_limit):\n",
    "                            rt_10_up.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_10_up.iloc[i,block_no]=np.nan\n",
    "        if (halt_type=='11'):\n",
    "            for i in range(len(rt_11_up.index)):\n",
    "                if (rt_11_up.iloc[i,0]==wtt_u.iloc[train_no,0]):\n",
    "                    if (lower_limit!=np.nan):\n",
    "                        if (rt_11_up.iloc[i,block_no]>upper_limit or rt_11_up.iloc[i,block_no]<lower_limit):\n",
    "                            rt_11_up.iloc[i,block_no]=np.nan\n",
    "                    else:\n",
    "                        rt_11_up.iloc[i,block_no]=np.nan       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sufiyan/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in (np.arange(0,54)): #(np.arange(0,54)):    TRAIN NUMBER HELD CONSTANT\n",
    "    y1_00_d = rt_00[rt_00['TrainMaskNo']==wtt_d.iloc[i,0]]\n",
    "    y1_01_d = rt_01[rt_01['TrainMaskNo']==wtt_d.iloc[i,0]]\n",
    "    y1_10_d = rt_10[rt_10['TrainMaskNo']==wtt_d.iloc[i,0]]\n",
    "    y1_11_d = rt_11[rt_11['TrainMaskNo']==wtt_d.iloc[i,0]]\n",
    "    y1_00_u = rt_00[rt_00['TrainMaskNo']==wtt_u.iloc[i,0]]\n",
    "    y1_01_u = rt_01[rt_01['TrainMaskNo']==wtt_u.iloc[i,0]]\n",
    "    y1_10_u = rt_10[rt_10['TrainMaskNo']==wtt_u.iloc[i,0]]\n",
    "    y1_11_u = rt_11[rt_11['TrainMaskNo']==wtt_u.iloc[i,0]]\n",
    "    for j in (np.arange(3,61)):  #(np.arange(3,61)):       BLOCK HELD CONSTANT\n",
    "        y_00_d = y1_00_d.iloc[:,j]    \n",
    "        y_01_d = y1_01_d.iloc[:,j]\n",
    "        y_10_d = y1_10_d.iloc[:,j]\n",
    "        y_11_d = y1_11_d.iloc[:,j]\n",
    "        y_00_u = y1_00_u.iloc[:,j]\n",
    "        y_01_u = y1_01_u.iloc[:,j]\n",
    "        y_10_u = y1_10_u.iloc[:,j]\n",
    "        y_11_u = y1_11_u.iloc[:,j]\n",
    "        y_c_00_d = np.count_nonzero(~np.isnan(y_00_d))\n",
    "        if (y_c_00_d>=35):\n",
    "            l_00_d, u_00_d = outlier(y_00_d)\n",
    "        else:\n",
    "            l_00_d, u_00_d = np.nan, np.nan      \n",
    "        remove_outlier(l_00_d,u_00_d,i,j,'D','00')\n",
    "        y_c_01_d = np.count_nonzero(~np.isnan(y_01_d))\n",
    "        if (y_c_01_d>=35):\n",
    "            l_01_d, u_01_d = outlier(y_01_d)\n",
    "        else:\n",
    "            l_01_d, u_01_d = np.nan, np.nan\n",
    "        remove_outlier(l_01_d,u_01_d,i,j,'D','01')\n",
    "        y_c_10_d = np.count_nonzero(~np.isnan(y_10_d))\n",
    "        if (y_c_10_d>=35):\n",
    "            l_10_d, u_10_d = outlier(y_10_d)\n",
    "        else:\n",
    "            l_10_d, u_10_d = np.nan, np.nan\n",
    "        remove_outlier(l_10_d,u_10_d,i,j,'D','10')\n",
    "        y_c_11_d = np.count_nonzero(~np.isnan(y_11_d))\n",
    "        if (y_c_11_d>=35):\n",
    "            l_11_d, u_11_d = outlier(y_11_d)\n",
    "        else:\n",
    "            l_11_d, u_11_d = np.nan, np.nan\n",
    "        remove_outlier(l_11_d,u_11_d,i,j,'D','11')\n",
    "        y_c_00_u = np.count_nonzero(~np.isnan(y_00_u))\n",
    "        if (y_c_00_u>=35):\n",
    "            l_00_u, u_00_u = outlier(y_00_u)\n",
    "        else:\n",
    "            l_00_u, u_00_u = np.nan, np.nan\n",
    "        remove_outlier(l_00_u,u_00_u,i,j,'U','00')\n",
    "        y_c_01_u = np.count_nonzero(~np.isnan(y_01_u))\n",
    "        if (y_c_01_u>=35):\n",
    "            l_01_u, u_01_u = outlier(y_01_u)\n",
    "        else:\n",
    "            l_01_u, u_01_u = np.nan, np.nan\n",
    "        remove_outlier(l_01_u,u_01_u,i,j,'U','01')\n",
    "        y_c_10_u = np.count_nonzero(~np.isnan(y_10_u))\n",
    "        if (y_c_10_u>=35):\n",
    "            l_10_u, u_10_u = outlier(y_10_u)\n",
    "        else:\n",
    "            l_10_u, u_10_u = np.nan, np.nan\n",
    "        remove_outlier(l_10_u,u_10_u,i,j,'U','10')\n",
    "        y_c_11_u = np.count_nonzero(~np.isnan(y_11_u))\n",
    "        if (y_c_11_u>=35):\n",
    "            l_11_u, u_11_u = outlier(y_11_u)\n",
    "        else:\n",
    "            l_11_u, u_11_u = np.nan, np.nan\n",
    "        remove_outlier(l_11_u,u_11_u,i,j,'U','11')\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_00_dn.to_csv('rt_00_dn.csv')\n",
    "rt_01_dn.to_csv('rt_01_dn.csv')\n",
    "rt_10_dn.to_csv('rt_10_dn.csv')\n",
    "rt_11_dn.to_csv('rt_11_dn.csv')\n",
    "rt_00_up.to_csv('rt_00_up.csv')\n",
    "rt_01_up.to_csv('rt_01_up.csv')\n",
    "rt_10_up.to_csv('rt_10_up.csv')\n",
    "rt_11_up.to_csv('rt_11_up.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
